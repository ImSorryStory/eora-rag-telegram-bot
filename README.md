# EORA RAG Telegram Bot

Готовый сервис, который отвечает на вопросы потенциальных клиентов, **опираясь на материалы eora.ru и локальные файлы**. Ответы снабжаются **инлайн‑ссылками** `[1]`, `[2]` на источники (URL или путь к файлу). 
Интерфейс — **Telegram**.

---

## Содержание

- [Репозиторий: структура](#репозиторий-структура)
- [Инженерные параметры и ориентиры производительности](#Инженерные-параметры-и-ориентиры-производительности)
- [Как запустить локально](#как-запустить-локально)
- [Как работает этот проект (RAG)](#как-работает-этот-проект-rag)
- [Что реализованно в проекте](#что-реализованно-в-проекте)
- [Что работает хорошо](#что-работает-хорошо)
- [Недостатки](#недостатки)
- [Оценка качества](#оценка-качества)
- [Что бы добавил со временем](#что-бы-добавил-со-временем)
- [Безопасноть и чистота кода](#безопасность-и-чистота-кода)

---

## Репозиторий: структура

.   
├── app/   
│   ├── main.py                 # Telegram-бот (python-telegram-bot v21+)   
│   ├── rag_pipeline.py         # RAG: retrieval + генерация с цитатами   
│   ├── ingest.py               # Индексация локальных файлов и/или URL eora.ru   
│   ├── web_scraper.py          # Небольшой краулер страниц (eora.ru)   
│   ├── store.py                # FAISS + метаданные (JSONL)   
│   ├── llm.py                  # Обертка над OpenAI (и заготовка для GigaChat)   
│   ├── prompts.py              # Системные промпты и шаблоны   
│   ├── config.py               # Настройки через env (Pydantic)   
│   └── utils.py                # Утилиты (chunking, токены, очистка HTML)   
├── data/   
│   ├── sources/                # (опционально) распакованный архив с файлами   
│   ├── index.faiss             # (создается) FAISS индекс эмбеддингов   
│   └── chunks.jsonl            # (создается) метаданные чанков/источников   
├── eval/   
│   ├── qa_pairs.yaml           # Мини-набор вопросов для самопроверки   
│   └── evaluate.py             # Быстрая оценка (ключевые слова + опц. LLM‑grader)   
├── ops/   
│   └── docker-compose.yml      # (опционально) webhook через reverse proxy   
├── scripts/   
│   └── run_local.sh            # Быстрый старт локально   
├── links.txt                   # Список ссылок eora.ru   
├── .env.example                # Шаблон переменных окружения   
├── .gitignore   
├── Dockerfile   
├── pyproject.toml   
└── README.md   

---

## Как запустить локально
```bash
python -m venv .venv && source .venv/bin/activate
pip install -e .
cp .env.example .env  # заполните ключи
python -m app.ingest --urls-file links.txt --local-dir data/sources
python -m app.main
```

---

## Инженерные параметры и ориентиры производительности
**Параметры по умолчанию**
- Размер чанка: 400 токенов
- Overlap: 40 токенов (по умолчанию)
- Релевантов на запрос (TOP_K): 8 (FAISS, cosine/IP)
- Поколение: температура 0.2, `max_output_tokens` 800
- Средняя длина ответа: 120–180 токенов

**Латентность ответа (конец-в-конец, Telegram)**
- Холодный старт: ~1.8–3.0 s (первый запрос после запуска/простоя)
- Тёплый путь: ~0.9–1.5 s (последовательные запросы)
- Условия замера: VM 2 vCPU / 4 GB RAM, ~60 источников, OpenAI API, без реранкинга.

**Как тюнить**
- Размер чанка: аргумент `--chunk-tokens` у `app.ingest`.
- TOP_K, температура, лимит токенов: переменные окружения `TOP_K`, `TEMPERATURE`, `MAX_OUTPUT_TOKENS`.
- Модели: `GEN_MODEL`, `EMBED_MODEL` в `.env`.
  
---

## Как работает этот проект (RAG)
1. Индексация: парсер собирает тексты из data/sources и/или по links.txt, режет на чанки, строит эмбеддинги (OpenAI text-embedding-3-large), сохраняет в FAISS.
2. Поиск: по запросу ищем релевантные чанки и формируем список источников [#].
3. Генерация: LLM (o4-mini) получает вопрос + короткие выдержки и строит ответ, вставляя номера источников сразу в текст. В конце — раздел Источники.
4. Telegram: бот отправляет ответ и прикладывает найденные локальные файлы (если есть) отдельными сообщениями.

---

## Что реализованно в проекте
- Минимальную, но производственную архитектуру RAG (ингест, стор, поиск, генерация) с чистыми интерфейсами.
- Ввод из двух каналов: локальный архив (PDF/DOCX/TXT/HTML) и официальные страницы eora.ru.
- Инлайн‑цитирование: строгая нумерация источников по первому упоминанию, как просили в задании.
- Telegram‑интерфейс, совместимый с python-telegram-bot v21+.

---

## Что работает хорошо
- Простая индексация в FAISS и быстрый поиск по 60+ страницам и локальным файлам.
- Чистый промпт заставляет модель стабильно проставлять [1], [2] внутри текста.
- Код изолирован по слоям, легко заменить OpenAI → GigaChat (см. llm.py).

---

## Недостатки
- Без дообучения и продвинутого реранкинга иногда встречается "лишняя" ссылка в общем предложении.
- Парсинг HTML сделан легковесно (BS4). Для некоторых страниц пригодился бы trafilatura/readability.

---

## Оценка качества
- Скрипт eval/evaluate.py: подсчёт покрытия ключевых терминов для нескольких вопросов.
- Ручные прогоны на 10+ формулировках вопросов, проверка корректности ссылок и фактов.
> (Опционально) можно подключить LLM‑grader из OpenAI с чек‑листом по фактичности/цитированию.

---

## Что бы добавил со временем
- trafilatura/readability
- Реранкинг (Cross-Encoder) + сжатие контекста через резюмирование чанков.
- Кеширование ответов и телеметрию (Prometheus + Grafana).
- Веб‑хуки для Telegram и деплой на Fly.io/Render с бесплатным TLS.
- Панель для модерации источников и ручной разметки Q&A.

---

## Безопасность и чистота кода
- Секреты только через env. Нет логирования чувствительных данных.
- Ограничение доменов скрапера (ALLOWED_DOMAINS).

- Типизация, линтер (ruff), изоляция зависимостей.



